
![](https://github.com/BigbangBang/learningNotes/picture/redis/redis集群.png)

## 主从复制（Master-Slave Replication）
适合场景：写少读多，单点写入，简单高可用。
一个主服务器，多个从服务器。主服务器同步数据到从服务器，从服务器只处理读请求。

### 同步过程
#### 第一次同步
1. 建立连接，协商同步数据。
2. 第一次同步。主服务器fork进程执行bgsave命令，生成RDB文件。同时将期间收到的写请求存入replication buffer缓冲区中。
3. 主服务器向从服务器同步RDB文件。
4. 从服务器处理完RDB文件后，向主服务器发送确认消息。接着主服务器将replication buffer缓存的命令发给从服务器。

_如果replication buffer满了会断开连接重新同步。_

### 完整重同步
1. 主服务器生成RDB文件，同步从服务器。
2. 记录期间的写命令到replication buffer中，在第一步完成后同步给从服务器。

### 部分重同步
主服务器维护环形缓冲区replication buffer，复制偏移量
从服务器维护复制偏移量
服务器的运行ID

#### 长连接同步
在第一次同步完成之后，主从服务器之间维护一个TCP长连接同步写操作，保证数据的一致性。

#### 增量复制
主服务器通过长连接将写操作同步给从服务器同时，会将命令写入环形缓冲区repl_backing_buffer（默认1M）。
主从服务器各自使用master_repl_offset、slave_repl_offset标记写读的位置。

1. 当主从服务器网络断开又重新连接时，从服务器通过psync命令将读slave_repl_offset偏移量告诉主服务器。
2. 主服务器在repl_backing_buffer中找出差异数据后，写入replication buffer中进行同步。

_如果断开连接期间缓冲区数据被覆盖，则进行全量同步。_


## 哨兵集群(Redis Sentinel)(主从+哨兵进程)
适合场景：中小规模系统，需要高可用但不需要分片。

redis在2.8版本之后提供了**哨兵(Sentinel)机制**，来实现主节点故障转移。监控主节点是否存活，如果主节点挂了就会从从节点中选一个节点切换为主节点，并把新主节点的相关信息通知给客户端和从节点。

### 监控主从节点
为了减少误判主从节点的状态，可以通过部署多个哨兵节点（3个）构成哨兵集群。通过多个哨兵节点一起判断，避免单个哨兵节点因为自身网络不好而误判。

#### 判断主节点故障
![](https://github.com/BigbangBang/learningNotes/picture/redis/sentinel_view.png)
当某个哨兵节点由于PING主从节点失败，就标记其为[主观下线]。并且该哨兵就作为[候选者]进行后续的投票和主从切换

并通知其他哨兵节点发起投票命令，根据投票结果判断节点是否下线。
哨兵集群配置quorum指定一个值，哨兵投票数达到该值后会客观标记主节点[客观下线]。

_quorum 的值建议设置为哨兵个数的二分之一加1,哨兵节点的数量应该是奇数。_

## 主从故障转移
1. 在已下线主节点的从节点中选一个作为新主节点。
2. 通知已下线主节点下的从节点改变复制目标为新主节点。
3. 将主节点的IP地址信息，通过发布订阅机制通知客户端。
4. 继续监视旧主节点，当旧主节点上线是，将其设为新主节点的从节点。

## Cluster集群（主从+分片）
适合场景：数据量大于单机内存上限，需要水平扩展读写能力。

该集群通过分片的方式存储键值对，集群整个数据库被分为16384（2^14）个槽位。节点只可以使用0号数据库。

使用redis-cli -c集群模式时，会自动转换到key对应的集群节点。
故障转移是通过集群主节点投票产生的。
```
127.0.0.1:7000  
127.0.0.1:7001  
127.0.0.1:7002  
127.0.0.1:7003  
127.0.0.1:7004  
127.0.0.1:7005

redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 --cluster-replicas 1
```
* 会自动选择3个节点为主节点
* 其余3个节点作为这3个主节点的从节点（每个节点配置一个从节点）（--cluster-replicas 1）
* 自动完成 CLUSTER MEET、SLOTS 分配和主从绑定。自动部署了cluster集群和slot的分配。
如果--cluster-replicas 0，表示不添加从节点。

在故障转移选择新的主节点使用的算法都是Raft算法的领头选举（leader election）方法来实现的。




